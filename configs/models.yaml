# æ¨¡å‹å®šä¹‰ - ä¸åç«¯æ— å…³
# æ¨¡å‹IDå¿…é¡»å”¯ä¸€ï¼Œç‹¬ç«‹äºåç«¯å®ç°

active_model: "qwen3:4b"  # ğŸ¯ å½“å‰æ¿€æ´»æ¨¡å‹
active_backend: "ollama"  # ğŸ¯ å½“å‰æ¿€æ´»åç«¯ï¼ˆollama/vllmï¼‰

models:
  qwen3:4b:
    name: "Qwen3-4B-Instruct"
    model_id: "qwen3:4b"
    
    # æ”¯æŒçš„åç«¯åˆ—è¡¨ï¼ˆå¯å¤šä¸ªï¼‰
    supported_backends:
      - "ollama"     # âœ… å®Œå…¨æ”¯æŒ
      - "vllm"       # âœ… éœ€è¦AWQé‡åŒ–ç‰ˆæœ¬
    
    # åç«¯ç‰¹å®šä»“åº“è·¯å¾„
    backend_repos:
      ollama: "qwen3:4b"
      vllm: "qwen/Qwen3-4B-Instruct-AWQ"  # AWQé‡åŒ–ç‰ˆ
    
    # èµ„æºè¦æ±‚ï¼ˆæ ¹æ®åç«¯åŠ¨æ€è°ƒæ•´ï¼‰
    resources:
      ollama:
        min_vram: "6GB"
        model_size: "4.3GB"
      vllm:
        min_vram: "5GB"  # AWQæ›´çœæ˜¾å­˜
        model_size: "2.1GB"
    
    # æ€§èƒ½å‚æ•°ï¼ˆåç«¯å¯è¦†ç›–ï¼‰
    parameters:
      temperature: 0.7
      top_p: 0.9
      max_tokens: 2048
    
    # èƒ½åŠ›æ ‡è®°ï¼ˆç‹¬ç«‹äºåç«¯ï¼‰
    capabilities:
      function_calling: true
      multi_agent: true
      rag: true
      code_generation: true

  qwen2.5:3b:
    name: "Qwen2.5-3B-Instruct"
    model_id: "qwen2.5:3b"
    
    # æ”¯æŒçš„åç«¯åˆ—è¡¨ï¼ˆå¯å¤šä¸ªï¼‰
    supported_backends:
      - "ollama"     # âœ… å®Œå…¨æ”¯æŒ
      - "vllm"       # âœ… éœ€è¦AWQé‡åŒ–ç‰ˆæœ¬
    
    # åç«¯ç‰¹å®šä»“åº“è·¯å¾„
    backend_repos:
      ollama: "qwen2.5:3b"
      vllm: "qwen/Qwen2.5-3B-Instruct-AWQ"
    
    # èµ„æºè¦æ±‚
    resources:
      ollama:
        min_vram: "4GB"
        model_size: "2.3GB"
      vllm:
        min_vram: "4GB"
        model_size: "2.1GB"
    
    parameters:
      temperature: 0.7
      top_p: 0.9
      max_tokens: 2048
    
    capabilities:
      function_calling: true
      multi_agent: true
      rag: true
      code_generation: true
